# Chapter 11: 多传感器融合算法

在现实应用中，单一传感器往往无法满足复杂环境下的感知需求。激光雷达虽然具有高精度测距能力，但在纹理信息、速度测量、全天候工作等方面存在局限。本章将详细介绍激光雷达与其他传感器的融合算法，包括相机、毫米波雷达、IMU和GPS的融合方法，以及在实际应用中的标定、同步和数据关联技术。通过多传感器融合，我们可以实现互补优势，提高感知系统的鲁棒性和准确性。

## 11.1 激光雷达+相机融合

激光雷达与相机的融合是最常见的多传感器组合，结合了激光雷达的精确深度信息和相机的丰富纹理信息。

### 11.1.1 投影矩阵与坐标转换

将激光雷达点云投影到相机图像需要经过多个坐标系转换：

**激光雷达坐标系到相机坐标系：**
```
P_camera = R_lidar_to_camera · P_lidar + t_lidar_to_camera
```

其中R是3×3旋转矩阵，t是3×1平移向量。

**相机坐标系到图像坐标系：**
```
[u]   [fx  0  cx] [X_camera/Z_camera]
[v] = [0  fy  cy] [Y_camera/Z_camera]
[1]   [0   0   1] [        1        ]
```

完整的投影矩阵：
```
P = K[R|t]
```

其中K是相机内参矩阵：
```
K = [fx  0  cx]
    [0  fy  cy]
    [0   0   1]
```

**计算实例：**
假设激光雷达点P_lidar = [10, 2, -0.5]^T (m)，外参标定结果为：
- 旋转角：roll=0°, pitch=5°, yaw=0°
- 平移：t = [0.1, 0, 0.2]^T (m)
- 相机内参：fx=fy=1000, cx=640, cy=360

计算过程：
1. 构建旋转矩阵（pitch=5°）：
   ```
   R = [1     0        0    ]
       [0  cos(5°)  -sin(5°)]
       [0  sin(5°)   cos(5°)]
   ```

2. 转换到相机坐标系：
   ```
   P_camera = R·[10, 2, -0.5]^T + [0.1, 0, 0.2]^T
            = [10.1, 1.957, -0.475]^T
   ```

3. 投影到图像：
   ```
   u = fx·X_camera/Z_camera + cx = 1000×10.1/(-0.475) + 640 = -20621
   ```

负的Z值表示点在相机后方，需要过滤。

### 11.1.2 时间同步策略

激光雷达和相机的采样频率不同，需要精确的时间同步：

**硬件同步：**
- PPS信号同步：精度可达μs级
- 触发信号：激光雷达触发相机曝光

**软件同步：**
- 时间戳对齐：寻找最近邻时间戳
- 插值方法：对运动物体进行插值补偿

**曝光中心对齐：**
相机的曝光时间不是瞬时的，需要计算曝光中心时刻：
```
t_center = t_start + t_exposure/2
```

对于全局快门相机，所有像素同时曝光；对于卷帘快门，需要考虑逐行扫描延迟：
```
t_row(y) = t_start + (y/height)×t_readout
```

### 11.1.3 特征级融合 - PointPainting

PointPainting是一种有效的特征级融合方法，将图像语义信息"绘制"到点云上：

1. **图像语义分割**：使用CNN获得每个像素的类别和置信度
2. **点云投影**：将每个3D点投影到图像平面
3. **语义赋值**：为每个点赋予对应像素的语义标签
4. **增强点云**：原始(x,y,z,r)扩展为(x,y,z,r,class_scores)

**实现细节：**
```
for each point p in pointcloud:
    (u,v) = project(p, K, R, t)
    if 0 <= u < width and 0 <= v < height:
        p.semantic = image_semantic[v,u]
        p.confidence = image_confidence[v,u]
```

### 11.1.4 深度补全算法

相机图像缺乏深度信息，而激光雷达点云稀疏，深度补全旨在生成稠密深度图：

**稀疏深度图生成：**
1. 初始化深度图D为全零
2. 投影点云到图像平面
3. 对每个投影点(u,v,d)：D[v,u] = d

**深度传播算法：**
基于图像引导的各向异性扩散：
```
∂D/∂t = div(g(∇I)·∇D)
```

其中g(∇I)是基于图像梯度的传导系数：
```
g(∇I) = exp(-|∇I|²/k²)
```

**双边滤波补全：**
```
D_dense(p) = Σ_q∈N(p) w_s(p,q)·w_r(I_p,I_q)·D_sparse(q) / Σw
```

其中：
- w_s：空间权重 = exp(-||p-q||²/2σ_s²)
- w_r：颜色权重 = exp(-||I_p-I_q||²/2σ_r²)

**计算实例：**
对于5×5邻域，中心像素深度缺失，周围有两个已知深度点：
- 点1：距离2像素，深度10m，颜色差异0.1
- 点2：距离3像素，深度12m，颜色差异0.3

设σ_s=2, σ_r=0.2：
```
w_1 = exp(-4/8)×exp(-0.01/0.08) = 0.606×0.882 = 0.535
w_2 = exp(-9/8)×exp(-0.09/0.08) = 0.324×0.324 = 0.105
D = (0.535×10 + 0.105×12)/(0.535+0.105) = 10.4m
```

### 11.1.5 融合架构设计

**前融合（Early Fusion）：**
- 在原始数据层面融合
- 将图像特征映射到点云或将点云投影到图像
- 优点：信息损失小
- 缺点：计算量大

**后融合（Late Fusion）：**
- 各传感器独立处理，融合检测结果
- 基于贝叶斯理论或D-S证据理论
- 优点：模块化好，易于扩展
- 缺点：信息利用不充分

**深度融合（Deep Fusion）：**
- 在神经网络中间层融合特征
- 多尺度特征融合
- 自适应融合权重

**融合网络示例：**
```
Image → CNN → Feature_I ↘
                         Fusion → Detection
LiDAR → PointNet → Feature_L ↗
```

## 11.2 激光雷达+毫米波雷达融合

毫米波雷达能够直接测量目标的径向速度，且在恶劣天气下工作稳定，与激光雷达形成良好互补。

### 11.2.1 速度信息融合

毫米波雷达通过多普勒效应测量径向速度：
```
f_d = 2v_r f_0/c
v_r = f_d·c/(2f_0)
```

其中f_0是载波频率（如77GHz），v_r是径向速度。

**卡尔曼滤波融合框架：**

状态向量：X = [x, y, z, vx, vy, vz]^T

状态转移方程：
```
X_k = F·X_{k-1} + w
F = [I₃  Δt·I₃]
    [0₃    I₃ ]
```

激光雷达观测模型（只有位置）：
```
Z_lidar = H_lidar·X + v_lidar
H_lidar = [I₃ 0₃]
```

毫米波雷达观测模型（位置+径向速度）：
```
Z_radar = h_radar(X) + v_radar
h_radar(X) = [x, y, z, (x·vx + y·vy + z·vz)/√(x²+y²+z²)]^T
```

**融合更新步骤：**
1. 预测：
   ```
   X̂_k|k-1 = F·X̂_{k-1}
   P_k|k-1 = F·P_{k-1}·F^T + Q
   ```

2. 激光雷达更新：
   ```
   K_lidar = P_k|k-1·H_lidar^T·(H_lidar·P_k|k-1·H_lidar^T + R_lidar)^{-1}
   X̂_k = X̂_k|k-1 + K_lidar·(Z_lidar - H_lidar·X̂_k|k-1)
   ```

3. 毫米波雷达更新（使用EKF）：
   ```
   H_radar = ∂h_radar/∂X|_{X̂_k}
   K_radar = P_k·H_radar^T·(H_radar·P_k·H_radar^T + R_radar)^{-1}
   X̂_k = X̂_k + K_radar·(Z_radar - h_radar(X̂_k))
   ```

**计算实例：**
目标在(10, 5, 0)m，速度(2, -1, 0)m/s：
- 激光雷达测量：(10.1, 4.9, 0.05)m
- 毫米波雷达测量：径向速度 v_r = (10×2 + 5×(-1))/√125 = 1.34m/s

径向速度验证：
```
v_r_true = (x·vx + y·vy)/r = (10×2 + 5×(-1))/11.18 = 1.34m/s ✓
```

### 11.2.2 检测置信度融合

不同传感器对不同目标的检测能力不同，需要融合置信度：

**D-S证据理论融合：**
基本概率分配（BPA）：
- m₁(A)：激光雷达认为是车辆的概率
- m₂(A)：毫米波雷达认为是车辆的概率

组合规则：
```
m(A) = Σ_{B∩C=A} m₁(B)·m₂(C) / (1-K)
K = Σ_{B∩C=∅} m₁(B)·m₂(C)
```

**示例计算：**
对于某目标：
- 激光雷达：m₁(车)=0.7, m₁(人)=0.2, m₁(不确定)=0.1
- 毫米波：m₂(车)=0.8, m₂(人)=0.1, m₂(不确定)=0.1

融合结果：
```
K = m₁(车)·m₂(人) + m₁(人)·m₂(车) = 0.7×0.1 + 0.2×0.8 = 0.23
m(车) = (0.7×0.8 + 0.7×0.1 + 0.1×0.8)/(1-0.23) = 0.71/0.77 = 0.922
m(人) = (0.2×0.1 + 0.2×0.1 + 0.1×0.1)/(1-0.23) = 0.05/0.77 = 0.065
```

### 11.2.3 恶劣天气互补

**雨雾衰减模型：**

激光雷达衰减（905nm）：
```
α_lidar_rain ≈ 0.2×R^0.6 dB/km (R: mm/h)
α_lidar_fog ≈ 13×V^{-0.6} dB/km (V: 能见度m)
```

毫米波雷达衰减（77GHz）：
```
α_radar_rain ≈ 0.003×R^1.2 dB/km
α_radar_fog ≈ 0.4 dB/km (轻雾)
```

**互补策略：**
1. 晴天：激光雷达权重0.8，毫米波0.2
2. 小雨（5mm/h）：激光雷达权重0.6，毫米波0.4
3. 大雨（50mm/h）：激光雷达权重0.3，毫米波0.7
4. 浓雾（V<50m）：激光雷达权重0.1，毫米波0.9

**自适应权重计算：**
```
w_lidar = exp(-α_lidar×R) / (exp(-α_lidar×R) + exp(-α_radar×R))
w_radar = 1 - w_lidar
```

### 11.2.4 数据关联算法

激光雷达和毫米波雷达的检测需要正确关联：

**最近邻关联：**
马氏距离：
```
d²_ij = (z_i - ẑ_j)^T·S^{-1}·(z_i - ẑ_j)
```
其中S是新息协方差矩阵。

**门限判断：**
```
d²_ij < χ²_α(n)
```
对于3维位置，95%置信度：χ²_{0.05}(3) = 7.815

**全局最优关联（匈牙利算法）：**
构建代价矩阵C，其中C_ij = d²_ij，求解：
```
min Σ_i Σ_j C_ij·x_ij
s.t. Σ_i x_ij = 1, Σ_j x_ij = 1, x_ij ∈ {0,1}
```

## 11.3 激光雷达+IMU融合

IMU（惯性测量单元）提供高频率的加速度和角速度测量，可以有效补偿激光雷达的运动畸变，提高SLAM精度。

### 11.3.1 紧耦合SLAM框架

**误差状态卡尔曼滤波（ESKF）：**

状态向量（15维）：
```
X = [δp, δv, δθ, δb_a, δb_g]^T
```
- δp：位置误差
- δv：速度误差  
- δθ：姿态误差（SO(3)李代数）
- δb_a：加速度计偏置误差
- δb_g：陀螺仪偏置误差

**连续时间运动方程：**
```
ṗ = v
v̇ = R(a - b_a - n_a) - g
Ṙ = R·[ω - b_g - n_g]×
ḃ_a = n_ba
ḃ_g = n_bg
```

**误差状态传播：**
```
δẋ = F·δx + G·n

F = [0   I   0     0      0   ]
    [0   0  -R[a]× -R     0   ]
    [0   0  -[ω]×  0     -I   ]
    [0   0   0     0      0   ]
    [0   0   0     0      0   ]
```

其中[a]×表示反对称矩阵：
```
[a]× = [ 0   -a_z  a_y]
       [ a_z  0   -a_x]
       [-a_y  a_x  0  ]
```

**离散化（中值积分）：**
```
δx_k = (I + F·Δt)·δx_{k-1} + G·n·√Δt
P_k = Φ·P_{k-1}·Φ^T + Q_d
```

### 11.3.2 IMU预积分理论

预积分避免了每次优化时重新积分IMU数据：

**位置预积分：**
```
Δp_{ij} = ∫_i^j ∫_i^t R_s(a_s - b_a)dsdt - (t_j-t_i)²g/2
```

**速度预积分：**
```
Δv_{ij} = ∫_i^j R_t(a_t - b_a)dt - (t_j-t_i)g
```

**旋转预积分：**
```
ΔR_{ij} = ∏_{k=i}^{j-1} Exp((ω_k - b_g)Δt)
```

其中Exp是SO(3)指数映射：
```
Exp(ω) = I + sin(||ω||)/||ω||·[ω]× + (1-cos(||ω||))/||ω||²·[ω]×²
```

**预积分测量的雅可比：**
对于偏置变化的一阶近似：
```
Δp̃_{ij} ≈ Δp_{ij} + J_p^{ba}·δb_a + J_p^{bg}·δb_g
Δṽ_{ij} ≈ Δv_{ij} + J_v^{ba}·δb_a + J_v^{bg}·δb_g
ΔR̃_{ij} ≈ ΔR_{ij}·Exp(J_R^{bg}·δb_g)
```

**计算实例：**
两个关键帧之间，IMU采样100Hz，持续0.5秒：
- 平均加速度：a = [0.1, 0, 9.85] m/s²（包含重力）
- 平均角速度：ω = [0, 0, 0.1] rad/s
- 偏置：b_a = [0.01, 0.01, 0], b_g = [0.001, 0.001, 0.002]

预积分结果：
```
Δv = ∫(a - b_a)dt - tg = [0.045, -0.005, 0.125] m/s
Δp = ∫∫(a - b_a)dtdt - t²g/2 = [0.011, -0.001, 0.031] m
ΔR = Exp((ω - b_g)t) ≈ Exp([0, 0, 0.049])
```

### 11.3.3 运动畸变校正

激光雷达扫描期间的运动导致点云畸变：

**线性插值方法：**
对于时刻t_i的点P_i，校正到参考时刻t_0：
```
P_0 = R_{0i}^{-1}(P_i - t_{0i})
```

其中R_{0i}和t_{0i}通过IMU积分获得：
```
R_{0i} = R_0·∏_{k=0}^{i-1} Exp(ω_k·Δt)
t_{0i} = Σ_{k=0}^{i-1} v_k·Δt + 0.5·a_k·Δt²
```

**去畸变算法流程：**
1. 对每个激光点，记录其时间戳t_i
2. 从IMU获取[t_0, t_i]期间的测量
3. 积分得到相对位姿变换
4. 将点变换到统一坐标系

**实际案例：**
车辆以20m/s行驶，激光雷达10Hz旋转：
- 一圈扫描时间：100ms
- 位移：20×0.1 = 2m
- 不校正误差：最大2m

使用IMU（200Hz）校正：
- 每5ms更新一次位姿
- 最大误差降至：20×0.005 = 0.1m

### 11.3.4 状态估计优化

**图优化框架：**
构建因子图，包含：
- IMU因子：基于预积分
- 激光雷达因子：点到面距离
- 回环因子：位姿约束

**代价函数：**
```
min Σ||r_IMU||²_{Σ_IMU} + Σ||r_LiDAR||²_{Σ_LiDAR} + Σ||r_loop||²_{Σ_loop}
```

**IMU残差：**
```
r_IMU = [R_i^T(p_j - p_i - v_i·Δt - g·Δt²/2) - Δp_{ij}]
        [R_i^T(v_j - v_i - g·Δt) - Δv_{ij}        ]
        [Log(ΔR_{ij}^T·R_i^T·R_j)                 ]
```

**LiDAR残差（点到面）：**
```
r_LiDAR = n^T·(R·p + t - q)
```
其中n是平面法向量，q是平面上的点。

**优化求解：**
使用Levenberg-Marquardt算法：
```
(J^T·W·J + λI)·Δx = -J^T·W·r
```

### 11.3.5 传感器标定

**IMU-LiDAR外参标定：**
旋转外参R_IL，平移外参t_IL

标定优化问题：
```
min Σ||p_L^j - R_IL·R_IB·(p_L^i - t_IL) - t_IL - R_IL·t_IB||²
```

**时间偏移标定：**
IMU和LiDAR可能存在时间偏移t_d：
```
t_IMU = t_LiDAR + t_d
```

通过最大化角速度相关性估计：
```
t_d = argmax Corr(ω_IMU(t), ω_LiDAR(t-τ))
```

## 11.4 激光雷达+GPS/RTK融合

GPS/RTK提供全局定位信息，可以消除SLAM的累积误差，实现大范围高精度定位。

### 11.4.1 全局定位融合框架

**图优化模型：**
节点：机器人位姿X_i = [x, y, z, roll, pitch, yaw]^T
边：
- 里程计边：相邻帧间的相对位姿
- GPS边：绝对位置约束
- 回环边：闭环检测约束

**代价函数：**
```
E = Σ||X_j ⊖ X_i ⊖ Z_{ij}^{odom}||²_{Σ_{ij}} 
  + Σ||p_i - Z_i^{GPS}||²_{Σ_{GPS}}
  + Σ||X_j ⊖ X_i ⊖ Z_{ij}^{loop}||²_{Σ_{loop}}
```

其中⊖表示SE(3)上的误差运算。

**GPS测量模型：**
```
Z_GPS = p_true + R_ENU·[σ_N·n_N, σ_E·n_E, σ_U·n_U]^T
```
- σ_N, σ_E, σ_U：北东天方向的标准差
- RTK定位：σ_N = σ_E ≈ 0.01m, σ_U ≈ 0.02m
- 普通GPS：σ_N = σ_E ≈ 2-5m, σ_U ≈ 5-10m

**ENU坐标转换：**
```
[E]   [-sin(lon)          cos(lon)           0    ] [X_ECEF]
[N] = [-sin(lat)cos(lon) -sin(lat)sin(lon)  cos(lat)] [Y_ECEF]
[U]   [cos(lat)cos(lon)   cos(lat)sin(lon)  sin(lat)] [Z_ECEF]
```

### 11.4.2 多路径效应处理

城市环境中的GPS信号受建筑物反射影响：

**多路径检测指标：**
1. C/N₀（载噪比）：< 35 dB-Hz表示信号弱
2. 仰角：< 15°的卫星易受多路径影响
3. DOP值：PDOP > 4表示几何构型差

**鲁棒估计方法：**
使用Huber损失函数：
```
ρ(e) = {
    0.5·e²,           |e| ≤ δ
    δ(|e| - 0.5δ),   |e| > δ
}
```

权重函数：
```
w(e) = {
    1,        |e| ≤ δ
    δ/|e|,    |e| > δ
}
```

**示例计算：**
GPS测量值与预测值偏差e = 5m，阈值δ = 2m：
- 二次损失：L = 0.5×5² = 12.5
- Huber损失：L = 2×(5-0.5×2) = 8
- 权重：w = 2/5 = 0.4

### 11.4.3 城市峡谷问题

高楼环境导致GPS信号遮挡和反射：

**可见性预测：**
使用激光雷达构建的3D地图预测卫星可见性：
```
Visible(sat_i) = RayCast(p_receiver, p_satellite) == clear
```

**天空视野因子（SVF）：**
```
SVF = Σ_visible cos(θ_elevation) / Σ_all cos(θ_elevation)
```

**融合策略：**
1. SVF > 0.7：正常融合GPS
2. 0.3 < SVF < 0.7：降低GPS权重
3. SVF < 0.3：仅依赖激光雷达SLAM

**自适应协方差调整：**
```
Σ_GPS_adjusted = Σ_GPS_base × (2 - SVF)²
```

### 11.4.4 松耦合vs紧耦合

**松耦合架构：**
- GPS/RTK独立解算位置
- 作为位置约束加入SLAM
- 优点：模块化，计算简单
- 缺点：未充分利用原始观测

**紧耦合架构：**
- 使用GPS原始伪距/载波相位观测
- 与激光雷达联合优化
- 优点：精度高，鲁棒性好
- 缺点：计算复杂

**伪距观测方程：**
```
ρ = ||p_sat - p_rec|| + c(dt_rec - dt_sat) + I + T + ε
```
- I：电离层延迟
- T：对流层延迟
- ε：多路径和噪声

### 11.4.5 初始化与收敛

**全局初始化：**
1. 等待GPS锁定（至少4颗卫星）
2. 静止30秒收集IMU数据估计初始姿态
3. 使用GPS位置和IMU姿态初始化

**局部到全局坐标转换：**
激光雷达SLAM通常在局部坐标系工作，需要估计到全局坐标系的变换：
```
T_global_local = argmin Σ||T·p_i^local - p_i^GPS||²
```

使用SVD求解：
1. 计算质心：p̄_local, p̄_GPS
2. 去质心：p'_i = p_i - p̄
3. 计算H = Σp'_local·p'_GPS^T
4. SVD分解：H = UΣV^T
5. 旋转：R = VU^T
6. 平移：t = p̄_GPS - R·p̄_local

**收敛监测：**
```
converged = (||Δposition|| < 0.1m) && (||Δorientation|| < 1°)
```

## 本章小结

本章详细介绍了激光雷达与相机、毫米波雷达、IMU和GPS/RTK的融合算法。主要知识点包括：

1. **激光雷达+相机融合**：
   - 投影矩阵计算：P = K[R|t]
   - 时间同步策略：硬件触发和软件插值
   - PointPainting特征融合
   - 深度补全算法

2. **激光雷达+毫米波雷达融合**：
   - 卡尔曼滤波框架融合速度信息
   - D-S证据理论融合检测置信度
   - 恶劣天气下的互补策略
   - 数据关联算法

3. **激光雷达+IMU融合**：
   - 误差状态卡尔曼滤波（ESKF）
   - IMU预积分理论：Δp, Δv, ΔR
   - 运动畸变校正
   - 紧耦合SLAM优化

4. **激光雷达+GPS/RTK融合**：
   - 图优化融合框架
   - 多路径效应和城市峡谷问题处理
   - 松耦合vs紧耦合架构
   - 坐标系转换和初始化

多传感器融合的核心是充分利用各传感器的优势，通过合理的数学框架实现信息互补，提高系统的鲁棒性和精度。在实际应用中，需要根据具体场景选择合适的融合策略。

## 练习题

### 基础题

1. **坐标转换计算**
   激光雷达检测到点P_lidar = [5, 3, 1]m，已知外参：R = Rz(30°), t = [0.2, 0.1, 0.3]m，相机内参fx=fy=800, cx=640, cy=480。计算该点在图像中的坐标。
   
   *Hint: 先进行坐标系转换，再投影到图像平面*
   
   <details>
   <summary>答案</summary>
   
   1. 旋转矩阵Rz(30°) = [[0.866, -0.5, 0], [0.5, 0.866, 0], [0, 0, 1]]
   2. P_camera = R·P_lidar + t = [3.03, 3.10, 1.3]m
   3. u = 800×3.03/1.3 + 640 = 2505, v = 800×3.10/1.3 + 480 = 2387
   </details>

2. **卡尔曼滤波预测**
   目标当前状态x=[10, 5, 2, -1]（位置和速度），Δt=0.1s，计算预测状态。
   
   *Hint: 使用匀速运动模型*
   
   <details>
   <summary>答案</summary>
   
   F = [[1, 0, 0.1, 0], [0, 1, 0, 0.1], [0, 0, 1, 0], [0, 0, 0, 1]]
   x_pred = F·x = [10.2, 4.9, 2, -1]
   </details>

3. **IMU预积分计算**
   IMU测量加速度a=[0.1, 0, 9.81]m/s²，角速度ω=[0, 0, 0.1]rad/s，时间间隔0.5s，计算速度和位置变化。
   
   *Hint: 忽略重力，假设初始速度为0*
   
   <details>
   <summary>答案</summary>
   
   Δv = a×t = [0.05, 0, 4.905]m/s
   Δp = 0.5×a×t² = [0.0125, 0, 1.226]m
   </details>

### 挑战题

4. **深度补全算法设计**
   设计一个基于双边滤波的深度补全算法，考虑颜色相似性和空间距离。给出权重计算公式和实现伪代码。
   
   *Hint: 参考双边滤波的数学形式*
   
   <details>
   <summary>答案</summary>
   
   权重：w(p,q) = exp(-||p-q||²/2σ_s²) × exp(-||I_p-I_q||²/2σ_r²)
   深度：D(p) = Σw(p,q)×D(q) / Σw(p,q)
   伪代码：遍历窗口内所有像素，计算权重，加权平均
   </details>

5. **多传感器时间同步**
   激光雷达10Hz，相机30Hz，IMU 200Hz。设计一个时间同步方案，确保数据对齐误差小于5ms。
   
   *Hint: 考虑硬件触发和软件插值*
   
   <details>
   <summary>答案</summary>
   
   1. 使用GPS的PPS信号作为公共时钟
   2. 激光雷达触发相机，确保3:1同步
   3. IMU数据通过插值对齐到激光雷达时刻
   4. 维护时间戳缓冲区，使用最近邻匹配
   </details>

6. **城市峡谷GPS融合策略**
   在城市峡谷环境中，设计一个自适应的GPS权重调整策略，考虑卫星数量、DOP值和信号强度。
   
   *Hint: 使用多个指标综合评估GPS质量*
   
   <details>
   <summary>答案</summary>
   
   质量因子Q = w1×(n_sat/12) + w2×(4/PDOP) + w3×(CNR/50)
   GPS权重 = min(Q, 1.0)
   当Q < 0.3时，完全依赖激光雷达SLAM
   </details>

7. **IMU零偏在线估计**
   设计一个算法，在车辆静止时在线估计IMU的加速度计和陀螺仪零偏。
   
   *Hint: 静止时理论加速度应为重力，角速度应为0*
   
   <details>
   <summary>答案</summary>
   
   静止检测：||a|| ∈ [9.7, 9.9] && ||ω|| < 0.01
   加速度计零偏：b_a = mean(a) - g_ref
   陀螺仪零偏：b_g = mean(ω)
   使用滑动窗口避免异常值
   </details>

8. **多传感器标定验证**
   设计一个实验方案，验证激光雷达-相机外参标定的准确性，要求精度达到像素级。
   
   *Hint: 使用标定板或自然特征点*
   
   <details>
   <summary>答案</summary>
   
   1. 使用棋盘格标定板，激光雷达提取平面，相机检测角点
   2. 投影激光雷达平面边缘到图像，计算与检测边缘的偏差
   3. 统计多个位置的重投影误差RMS
   4. 误差应小于2像素，否则重新标定
   </details>