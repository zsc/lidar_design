<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>Chapter 11: 多传感器融合算法</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">激光雷达完整技术教程</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 1: 激光雷达基础原理</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 2: 激光雷达技术发展与主要厂商</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 3: 激光雷达类型与扫描机制</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 4: 激光雷达制造技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 5: 信号处理与时序控制</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 6: 误差源分析（非信号处理）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 7: 激光雷达独特优势与性能极限</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 8: 点云处理基础算法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 9: 高级点云算法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 10: 标定技术</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 11: 多传感器融合算法</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 12: 自动驾驶专用章节</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 13: 机器人应用（人形与仓储）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Chapter 14: 其他应用领域</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">激光雷达教程项目说明</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="chapter-11">Chapter 11: 多传感器融合算法</h1>
<p>在现实应用中，单一传感器往往无法满足复杂环境下的感知需求。激光雷达虽然具有高精度测距能力，但在纹理信息、速度测量、全天候工作等方面存在局限。本章将详细介绍激光雷达与其他传感器的融合算法，包括相机、毫米波雷达、IMU和GPS的融合方法，以及在实际应用中的标定、同步和数据关联技术。通过多传感器融合，我们可以实现互补优势，提高感知系统的鲁棒性和准确性。</p>
<h2 id="111">11.1 激光雷达+相机融合</h2>
<p>激光雷达与相机的融合是最常见的多传感器组合，结合了激光雷达的精确深度信息和相机的丰富纹理信息。这种融合在自动驾驶、机器人导航和三维重建等领域具有广泛应用。</p>
<h3 id="1111">11.1.1 投影矩阵与坐标转换</h3>
<p>将激光雷达点云投影到相机图像需要经过多个坐标系转换，理解这些转换的数学原理至关重要。</p>
<p><strong>坐标系定义：</strong></p>
<ul>
<li>激光雷达坐标系：X轴向前，Y轴向左，Z轴向上（右手系）</li>
<li>相机坐标系：X轴向右，Y轴向下，Z轴向前（光轴方向）</li>
<li>图像坐标系：原点在左上角，u轴向右，v轴向下</li>
</ul>
<p><strong>激光雷达坐标系到相机坐标系：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">P_camera</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">R_lidar_to_camera</span><span class="w"> </span><span class="err">·</span><span class="w"> </span><span class="n">P_lidar</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">t_lidar_to_camera</span>
</code></pre></div>

<p>其中R是3×3旋转矩阵，t是3×1平移向量。旋转矩阵可通过欧拉角或四元数表示：</p>
<p>欧拉角表示（ZYX顺序）：</p>
<div class="codehilite"><pre><span></span><code>R = R_z(yaw) · R_y(pitch) · R_x(roll)

R_x(φ) = [1    0       0    ]
         [0  cos(φ) -sin(φ)]
         [0  sin(φ)  cos(φ)]

R_y(θ) = [ cos(θ)  0  sin(θ)]
         [   0     1    0   ]
         [-sin(θ)  0  cos(θ)]

R_z(ψ) = [cos(ψ) -sin(ψ)  0]
         [sin(ψ)  cos(ψ)  0]
         [  0       0      1]
</code></pre></div>

<p><strong>相机坐标系到图像坐标系：</strong>
透视投影模型：</p>
<div class="codehilite"><pre><span></span><code><span class="n">λ</span><span class="o">[</span><span class="n">u</span><span class="o">]</span><span class="w">   </span><span class="o">[</span><span class="n">fx  s  cx</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">X_camera</span><span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="n">v</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">0  fy  cy</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">Y_camera</span><span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="w">   </span><span class="o">[</span><span class="n">0   0   1</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">Z_camera</span><span class="o">]</span>
</code></pre></div>

<p>其中：</p>
<ul>
<li>fx, fy：焦距（像素单位）</li>
<li>cx, cy：主点坐标</li>
<li>s：倾斜参数（通常为0）</li>
<li>λ = Z_camera：深度值</li>
</ul>
<p><strong>畸变校正：</strong>
实际相机存在径向和切向畸变：</p>
<div class="codehilite"><pre><span></span><code>径向畸变：
x_distorted = x(1 + k1·r² + k2·r⁴ + k3·r⁶)
y_distorted = y(1 + k1·r² + k2·r⁴ + k3·r⁶)

切向畸变：
x_distorted = x + 2p1·xy + p2(r² + 2x²)
y_distorted = y + p1(r² + 2y²) + 2p2·xy
</code></pre></div>

<p>其中r² = x² + y²，(x,y)是归一化相机坐标。</p>
<p><strong>完整投影流程：</strong></p>
<ol>
<li>3D点从激光雷达坐标系转换到相机坐标系</li>
<li>检查点是否在相机前方（Z_camera &gt; 0）</li>
<li>归一化：x = X_camera/Z_camera, y = Y_camera/Z_camera</li>
<li>应用畸变模型</li>
<li>投影到像素坐标</li>
</ol>
<p><strong>计算实例1（标准情况）：</strong>
激光雷达点P_lidar = [10, 2, -0.5]^T (m)，外参标定结果：</p>
<ul>
<li>旋转角：roll=0°, pitch=5°, yaw=0°</li>
<li>平移：t = [0.1, 0, 0.2]^T (m)</li>
<li>相机内参：fx=fy=1000, cx=640, cy=360</li>
<li>畸变系数：k1=-0.1, k2=0.05, p1=p2=0</li>
</ul>
<p>计算过程：</p>
<ol>
<li>构建旋转矩阵（pitch=5°≈0.0873rad）：</li>
</ol>
<div class="codehilite"><pre><span></span><code>R = [1      0         0     ]
    [0   0.9962   -0.0872 ]
    [0   0.0872    0.9962 ]
</code></pre></div>

<ol start="2">
<li>转换到相机坐标系：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="n">P_camera</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">R</span><span class="err">·</span><span class="n">P_lidar</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="k">t</span>
<span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mf">10.1</span><span class="p">,</span><span class="w"> </span><span class="mf">2.036</span><span class="p">,</span><span class="w"> </span><span class="mf">0.674</span><span class="p">]</span><span class="err">^</span><span class="n">T</span>
</code></pre></div>

<ol start="3">
<li>归一化坐标：</li>
</ol>
<div class="codehilite"><pre><span></span><code>x = 10.1/0.674 = 14.985
y = 2.036/0.674 = 3.021
</code></pre></div>

<ol start="4">
<li>畸变校正：</li>
</ol>
<div class="codehilite"><pre><span></span><code>r² = 14.985² + 3.021² = 233.65
畸变因子 = 1 + (-0.1)×233.65 + 0.05×233.65² = -729.8
</code></pre></div>

<p>极端畸变表明点在图像边缘，需要更合理的参数。</p>
<p><strong>计算实例2（实际车载场景）：</strong>
激光雷达检测到前方车辆点P_lidar = [20, -1.5, 0.8]^T：</p>
<ul>
<li>外参：roll=0.5°, pitch=-2°, yaw=1°</li>
<li>平移：t = [0.05, -0.08, 0.15]^T</li>
<li>内参：fx=1200, fy=1200, cx=960, cy=540</li>
</ul>
<p>详细计算：</p>
<ol>
<li>组合旋转矩阵：</li>
</ol>
<div class="codehilite"><pre><span></span><code>R = [ 0.9997  -0.0175   0.0174]
    [ 0.0178   0.9996  -0.0087]
    [-0.0171   0.0093   0.9998]
</code></pre></div>

<ol start="2">
<li>坐标转换：</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="n">P_camera</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mf">20.02</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mf">1.45</span><span class="p">,</span><span class="w"> </span><span class="mf">0.51</span><span class="p">]</span><span class="err">^</span><span class="n">T</span>
</code></pre></div>

<ol start="3">
<li>投影（忽略畸变）：</li>
</ol>
<div class="codehilite"><pre><span></span><code>u = 1200×20.02/0.51 + 960 = 48082
v = 1200×(-1.45)/0.51 + 540 = -2872
</code></pre></div>

<p>点在图像范围外，说明需要更大的视场角相机。</p>
<p><strong>边界条件处理：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">project_lidar_to_image</span><span class="p">(</span><span class="n">P_lidar</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dist_coeffs</span><span class="p">,</span> <span class="n">img_width</span><span class="p">,</span> <span class="n">img_height</span><span class="p">):</span>
    <span class="c1"># 转换到相机坐标系</span>
    <span class="n">P_cam</span> <span class="o">=</span> <span class="n">R</span> <span class="o">@</span> <span class="n">P_lidar</span> <span class="o">+</span> <span class="n">t</span>

    <span class="c1"># 检查深度</span>
    <span class="k">if</span> <span class="n">P_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>  <span class="c1"># 点在相机后方</span>

    <span class="c1"># 归一化</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">P_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">P_cam</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">P_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># 畸变校正</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span>
    <span class="k">if</span> <span class="n">r2</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>  <span class="c1"># 防止数值溢出</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># 投影</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">y</span> <span class="o">+</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># 边界检查</span>
    <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">img_width</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">img_height</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div>

<h3 id="1112">11.1.2 时间同步策略</h3>
<p>激光雷达和相机的采样频率不同，需要精确的时间同步。时间不同步会导致运动物体的错位，严重影响融合精度。</p>
<p><strong>传感器时序特性：</strong></p>
<ul>
<li>激光雷达：连续旋转扫描，每个点有独立时间戳</li>
<li>相机：离散采样，整帧或逐行曝光</li>
<li>典型频率：激光雷达10-20Hz，相机30-60Hz</li>
</ul>
<p><strong>硬件同步方案：</strong></p>
<ol>
<li><strong>PPS（Pulse Per Second）同步：</strong>
   - GPS提供1Hz脉冲信号，精度±50ns
   - 所有传感器锁定到同一PPS源
   - 时间戳格式：GPS时间 + 亚秒偏移</li>
</ol>
<div class="codehilite"><pre><span></span><code>t_sensor = t_GPS_week × 604800 + t_GPS_second + Δt_subsecond
</code></pre></div>

<ol start="2">
<li><strong>主从触发模式：</strong>
   - 激光雷达作为主设备，输出同步脉冲
   - 相机接收触发信号，延迟Δt后曝光
   - 触发延迟计算：</li>
</ol>
<div class="codehilite"><pre><span></span><code>Δt_trigger = t_lidar_center - t_exposure/2 - t_trigger_delay
</code></pre></div>

<ol start="3">
<li><strong>IEEE 1588 PTP同步：</strong>
   - 精确时间协议，精度可达亚微秒级
   - 主时钟广播，从设备同步
   - 延迟补偿：</li>
</ol>
<div class="codehilite"><pre><span></span><code>t_offset = (t_m2 - t_m1 + t_s1 - t_s2) / 2
t_delay = (t_m2 - t_m1 + t_s2 - t_s1) / 2
</code></pre></div>

<p><strong>软件同步算法：</strong></p>
<ol>
<li><strong>最近邻匹配：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">find_nearest_timestamp</span><span class="p">(</span><span class="n">target_time</span><span class="p">,</span> <span class="n">timestamps</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">timestamps</span><span class="p">,</span> <span class="n">target_time</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timestamps</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">timestamps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">before</span> <span class="o">=</span> <span class="n">timestamps</span><span class="p">[</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">after</span> <span class="o">=</span> <span class="n">timestamps</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">after</span> <span class="o">-</span> <span class="n">target_time</span> <span class="o">&lt;</span> <span class="n">target_time</span> <span class="o">-</span> <span class="n">before</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">idx</span>
    <span class="k">return</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span>
</code></pre></div>

<ol start="2">
<li><strong>线性插值：</strong>
   对于运动补偿，需要插值传感器位姿：</li>
</ol>
<div class="codehilite"><pre><span></span><code>α = (t_target - t_before) / (t_after - t_before)
P_interpolated = (1 - α) × P_before + α × P_after
R_interpolated = Slerp(R_before, R_after, α)
</code></pre></div>

<p>其中Slerp是球面线性插值：
   <code>Slerp(q0, q1, α) = sin((1-α)Ω)/sin(Ω) × q0 + sin(αΩ)/sin(Ω) × q1
   Ω = arccos(q0·q1)</code></p>
<p><strong>曝光模型详解：</strong></p>
<ol>
<li><strong>全局快门（Global Shutter）：</strong>
   - 所有像素同时曝光
   - 时间戳对应曝光中心：</li>
</ol>
<div class="codehilite"><pre><span></span><code>t_center = t_trigger + t_delay + t_exposure/2
</code></pre></div>

<p>运动模糊模型：
   <code>I_blur = ∫[0 to t_exp] I(t) dt / t_exposure</code></p>
<ol start="2">
<li><strong>卷帘快门（Rolling Shutter）：</strong>
   - 逐行扫描，产生果冻效应
   - 每行时间戳：</li>
</ol>
<div class="codehilite"><pre><span></span><code>t_row(y) = t_start + (y/H) × t_readout
t_readout ≈ 1/fps - t_exposure
</code></pre></div>

<p>畸变校正：
   <code>对于每行y：
   Δt = t_row(y) - t_reference
   x_corrected = x - v_x × Δt</code></p>
<p><strong>时间同步质量评估：</strong></p>
<ol>
<li><strong>同步误差测量：</strong>
   使用旋转标定板，计算投影误差：</li>
</ol>
<div class="codehilite"><pre><span></span><code>ε_sync = ||P_projected - P_detected||
</code></pre></div>

<p>理论误差模型：
   <code>ε = v × Δt_sync + ω × r × Δt_sync</code>
   其中v是线速度，ω是角速度，r是到旋转中心距离。</p>
<ol start="2">
<li><strong>实例计算：</strong>
   车辆以20m/s行驶，相机30Hz，激光雷达10Hz：</li>
</ol>
<ul>
<li>最大时间差：1/10 = 100ms</li>
<li>不同步最大误差：20 × 0.1 = 2m</li>
<li>使用插值后：误差 &lt; 20 × 0.001 = 2cm</li>
</ul>
<p><strong>多传感器时间对齐流程：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MultiSensorSync</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sync_tolerance</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>  <span class="c1"># 50ms容差</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync_tolerance</span> <span class="o">=</span> <span class="n">sync_tolerance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">add_measurement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sensor_id</span><span class="p">,</span> <span class="n">timestamp</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">sensor_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="p">[</span><span class="n">sensor_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">deque</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="p">[</span><span class="n">sensor_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">timestamp</span><span class="p">,</span> <span class="n">data</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">try_sync</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">try_sync</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="c1"># 找到最新的共同时间戳</span>
        <span class="n">latest_times</span> <span class="o">=</span> <span class="p">{</span><span class="n">sid</span><span class="p">:</span> <span class="n">q</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">sid</span><span class="p">,</span> <span class="n">q</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">q</span><span class="p">}</span>
        <span class="n">sync_time</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">latest_times</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="c1"># 检查是否所有传感器都有接近的数据</span>
        <span class="n">synced_data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">sid</span><span class="p">,</span> <span class="n">queue</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sensor_queues</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">closest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">find_closest</span><span class="p">(</span><span class="n">queue</span><span class="p">,</span> <span class="n">sync_time</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">closest</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">sync_time</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">sync_tolerance</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>
            <span class="n">synced_data</span><span class="p">[</span><span class="n">sid</span><span class="p">]</span> <span class="o">=</span> <span class="n">closest</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">sync_time</span><span class="p">,</span> <span class="n">synced_data</span>
</code></pre></div>

<h3 id="1113-pointpainting">11.1.3 特征级融合 - PointPainting</h3>
<p>PointPainting是一种有效的特征级融合方法，将图像语义信息"绘制"到点云上，显著提升3D检测性能。</p>
<p><strong>算法原理：</strong></p>
<p>PointPainting利用成熟的2D语义分割网络增强3D点云，核心思想是将每个3D点投影到图像平面，获取对应像素的语义信息，然后将这些信息作为额外特征附加到点云上。</p>
<p><strong>详细流程：</strong></p>
<ol>
<li><strong>图像语义分割：</strong>
   使用预训练的语义分割网络（如DeepLab、Mask R-CNN）：</li>
</ol>
<div class="codehilite"><pre><span></span><code>输入：RGB图像 I ∈ R^(H×W×3)
输出：语义概率图 S ∈ R^(H×W×C)
其中C是类别数，S[i,j,k]表示像素(i,j)属于类别k的概率
</code></pre></div>

<ol start="2">
<li><strong>点云投影与语义映射：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">point_painting</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">seg_model</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="c1"># 语义分割</span>
    <span class="n">semantic_probs</span> <span class="o">=</span> <span class="n">seg_model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  <span class="c1"># H×W×C</span>

    <span class="c1"># 初始化增强特征</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="n">semantic_probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">painted_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">),</span> <span class="n">num_classes</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">points</span><span class="p">):</span>
        <span class="c1"># 投影到图像</span>
        <span class="n">p_cam</span> <span class="o">=</span> <span class="n">R</span> <span class="o">@</span> <span class="n">point</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="n">t</span>
        <span class="k">if</span> <span class="n">p_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">u</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">p_cam</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">p_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
        <span class="n">v</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">p_cam</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">p_cam</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>

        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">u</span> <span class="o">&lt;</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">painted_features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">semantic_probs</span><span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">]</span>

    <span class="c1"># 拼接原始点云和语义特征</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">points</span><span class="p">,</span> <span class="n">painted_features</span><span class="p">])</span>
</code></pre></div>

<ol start="3">
<li><strong>特征编码策略：</strong></li>
</ol>
<p>a) <strong>One-hot编码：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">class_id</span> = <span class="n">argmax</span>(<span class="n">semantic_probs</span>)
<span class="n">one_hot</span> = [<span class="mi">0</span>, ..., <span class="mi">1</span>, ..., <span class="mi">0</span>]  <span class="c1"># 仅class_id位置为1</span>
</code></pre></div>

<p>b) <strong>概率分布编码：</strong>
   <code>features = semantic_probs  # 保留所有类别概率</code></p>
<p>c) <strong>Top-k编码：</strong>
   <code>top_k_classes = argsort(semantic_probs)[-k:]
   features = [class_ids, probabilities]</code></p>
<ol start="4">
<li><strong>处理投影歧义：</strong></li>
</ol>
<p>多个点可能投影到同一像素，需要深度排序：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">resolve_projection_ambiguity</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">projections</span><span class="p">):</span>
    <span class="n">pixel_dict</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">depth</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">projections</span><span class="p">):</span>
        <span class="n">pixel_dict</span><span class="p">[(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">depth</span><span class="p">))</span>

    <span class="c1"># 保留最近的点</span>
    <span class="n">valid_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pixel</span><span class="p">,</span> <span class="n">point_list</span> <span class="ow">in</span> <span class="n">pixel_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">nearest</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">point_list</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">valid_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nearest</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">valid_indices</span>
</code></pre></div>

<p><strong>性能优化：</strong></p>
<ol>
<li><strong>批处理投影：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="c1"># 向量化投影计算</span>
<span class="n">P_cam</span> <span class="o">=</span> <span class="p">(</span><span class="n">R</span> <span class="o">@</span> <span class="n">points</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">t</span>
<span class="n">valid_mask</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">P_cam</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[</span><span class="n">valid_mask</span><span class="p">]</span>

<span class="n">uv</span> <span class="o">=</span> <span class="n">K</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">@</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">K</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div>

<ol start="2">
<li><strong>GPU加速：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">projectPoints</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">points</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">K</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">RT</span><span class="p">,</span><span class="w"> </span>
<span class="w">                              </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">uv_coords</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">num_points</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">blockDim</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">idx</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="n">num_points</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// 3D变换</span>
<span class="w">    </span><span class="kt">float3</span><span class="w"> </span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_float3</span><span class="p">(</span><span class="n">points</span><span class="p">[</span><span class="n">idx</span><span class="o">*</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">points</span><span class="p">[</span><span class="n">idx</span><span class="o">*</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">points</span><span class="p">[</span><span class="n">idx</span><span class="o">*</span><span class="mi">3</span><span class="o">+</span><span class="mi">2</span><span class="p">]);</span>
<span class="w">    </span><span class="kt">float3</span><span class="w"> </span><span class="n">p_cam</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">matmul</span><span class="p">(</span><span class="n">RT</span><span class="p">,</span><span class="w"> </span><span class="n">p</span><span class="p">);</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">p_cam</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">uv_coords</span><span class="p">[</span><span class="n">idx</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p_cam</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">p_cam</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">        </span><span class="n">uv_coords</span><span class="p">[</span><span class="n">idx</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">K</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">p_cam</span><span class="p">.</span><span class="n">y</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">p_cam</span><span class="p">.</span><span class="n">z</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">K</span><span class="p">[</span><span class="mi">5</span><span class="p">];</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>实验验证：</strong></p>
<p>在KITTI数据集上的性能提升：</p>
<ul>
<li>基线（仅点云）：Car AP@0.7 = 79.8%</li>
<li>PointPainting：Car AP@0.7 = 82.1% (+2.3%)</li>
<li>对小物体提升更明显：Pedestrian AP提升+4.5%</li>
</ul>
<p><strong>扩展应用：</strong></p>
<ol>
<li><strong>实例级PointPainting：</strong>
   使用实例分割替代语义分割：</li>
</ol>
<div class="codehilite"><pre><span></span><code>features = [semantic_class, instance_id, confidence]
</code></pre></div>

<ol start="2">
<li><strong>时序PointPainting：</strong>
   融合多帧语义信息：</li>
</ol>
<div class="codehilite"><pre><span></span><code>semantic_t = α × semantic_t + (1-α) × semantic_{t-1}
</code></pre></div>

<ol start="3">
<li><strong>自监督PointPainting：</strong>
   使用伪标签训练：</li>
</ol>
<div class="codehilite"><pre><span></span><code>pseudo_labels = threshold(teacher_model(image), τ)
painted_points = point_painting(points, pseudo_labels)
</code></pre></div>

<h3 id="1114">11.1.4 深度补全算法</h3>
<p>相机图像缺乏深度信息，而激光雷达点云稀疏（64线激光雷达仅覆盖约5%的图像像素），深度补全旨在生成稠密深度图，这对于许多下游任务如3D重建、增强现实等至关重要。</p>
<p><strong>问题定义：</strong></p>
<ul>
<li>输入：稀疏深度图D_sparse ∈ R^(H×W)，RGB图像I ∈ R^(H×W×3)</li>
<li>输出：稠密深度图D_dense ∈ R^(H×W)</li>
<li>目标：min ||D_dense - D_gt||，同时保持边缘对齐</li>
</ul>
<p><strong>稀疏深度图生成：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">generate_sparse_depth</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">):</span>
    <span class="n">depth_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">))</span>
    <span class="n">confidence_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">img_height</span><span class="p">,</span> <span class="n">img_width</span><span class="p">))</span>

    <span class="c1"># 投影点云</span>
    <span class="n">P_cam</span> <span class="o">=</span> <span class="p">(</span><span class="n">R</span> <span class="o">@</span> <span class="n">points</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">t</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">P_cam</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span>

    <span class="c1"># 计算图像坐标</span>
    <span class="n">uv</span> <span class="o">=</span> <span class="n">K</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">@</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="n">P_cam</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">K</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">uv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">uv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># 处理重叠：Z-buffer</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">u</span><span class="p">)):</span>
        <span class="k">if</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">img_width</span> <span class="ow">and</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">img_height</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">depth_map</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">P_cam</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">depth_map</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]]:</span>
                <span class="n">depth_map</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
                <span class="n">confidence_map</span><span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">P_cam</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>  <span class="c1"># 反射强度作为置信度</span>

    <span class="k">return</span> <span class="n">depth_map</span><span class="p">,</span> <span class="n">confidence_map</span>
</code></pre></div>

<p><strong>经典方法：</strong></p>
<ol>
<li><strong>图像引导的各向异性扩散：</strong></li>
</ol>
<p>PDE形式：</p>
<div class="codehilite"><pre><span></span><code>∂D/∂t = div(g(∇I)·∇D)
</code></pre></div>

<p>离散化实现：
   <code>D^(n+1) = D^n + λ·[g_N·(D_N-D) + g_S·(D_S-D) + g_E·(D_E-D) + g_W·(D_W-D)]</code></p>
<p>其中传导系数：
   <code>g_N = exp(-||I - I_N||²/k²)
   g_S = exp(-||I - I_S||²/k²)
   g_E = exp(-||I - I_E||²/k²)
   g_W = exp(-||I - I_W||²/k²)</code></p>
<p>参数选择：</p>
<ul>
<li>λ = 0.25（稳定性条件）</li>
<li>k = 0.1×(I_max - I_min)（边缘阈值）</li>
<li>迭代次数：100-500</li>
</ul>
<ol start="2">
<li><strong>双边滤波深度补全：</strong></li>
</ol>
<p>完整公式：</p>
<div class="codehilite"><pre><span></span><code>D_dense(p) = Σ_{q∈Ω(p)} w_s(p,q)·w_r(I_p,I_q)·w_d(D_q)·D_sparse(q) / W
</code></pre></div>

<p>权重函数：</p>
<ul>
<li>空间权重：w_s(p,q) = exp(-||p-q||²/2σ_s²)</li>
<li>颜色权重：w_r(I_p,I_q) = exp(-||I_p-I_q||²/2σ_r²)</li>
<li>深度置信度：w_d(D_q) = exp(-|D_q|/σ_d) if D_q &gt; 0, else 0</li>
<li>归一化：W = Σw_s·w_r·w_d</li>
</ul>
<p>多尺度策略：</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">multiscale_bilateral_filter</span><span class="p">(</span><span class="n">D_sparse</span><span class="p">,</span> <span class="n">I</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]):</span>
    <span class="n">D_result</span> <span class="o">=</span> <span class="n">D_sparse</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="n">scales</span><span class="p">:</span>
        <span class="c1"># 下采样</span>
        <span class="n">D_s</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="n">D_result</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
        <span class="n">I_s</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>

        <span class="c1"># 双边滤波</span>
        <span class="n">D_s</span> <span class="o">=</span> <span class="n">bilateral_filter</span><span class="p">(</span><span class="n">D_s</span><span class="p">,</span> <span class="n">I_s</span><span class="p">,</span> <span class="n">σ_s</span><span class="o">=</span><span class="mi">3</span><span class="o">*</span><span class="n">scale</span><span class="p">,</span> <span class="n">σ_r</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="c1"># 上采样并融合</span>
        <span class="n">D_up</span> <span class="o">=</span> <span class="n">upsample</span><span class="p">(</span><span class="n">D_s</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">D_result</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="n">D_result</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">D_up</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">D_result</span>
</code></pre></div>

<ol start="3">
<li><strong>马尔可夫随机场（MRF）方法：</strong></li>
</ol>
<p>能量函数：</p>
<div class="codehilite"><pre><span></span><code>E(D) = Σ_p φ_d(D_p) + λ·Σ_{p,q∈N} φ_s(D_p, D_q, I_p, I_q)
</code></pre></div>

<p>数据项：
   <code>φ_d(D_p) = {
       (D_p - D_sparse(p))² if D_sparse(p) &gt; 0
       0                     otherwise
   }</code></p>
<p>平滑项：
   <code>φ_s(D_p, D_q, I_p, I_q) = min(|D_p - D_q|, τ_d) × exp(-||I_p - I_q||/τ_i)</code></p>
<p><strong>深度学习方法：</strong></p>
<ol>
<li><strong>卷积神经网络架构：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>输入：[D_sparse, I] ∈ R^(H×W×4)
编码器：ResNet骨干网络提取多尺度特征
解码器：上采样 + 跳跃连接
输出：D_dense ∈ R^(H×W×1)
</code></pre></div>

<ol start="2">
<li><strong>损失函数设计：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>L_total = λ_1·L_depth + λ_2·L_smooth + λ_3·L_normal

L_depth = ||D_pred - D_gt||_1
L_smooth = Σ|∇D_pred|·exp(-|∇I|)
L_normal = 1 - cos(n_pred, n_gt)
</code></pre></div>

<p><strong>实际计算示例：</strong></p>
<p>场景：5×5窗口深度补全</p>
<div class="codehilite"><pre><span></span><code>稀疏深度图：        RGB强度图：
[0  0  0  0  0]    [120 125 130 135 140]
[0  10 0  0  0]    [115 120 125 130 135]
[0  0  ?  0  0]    [110 115 120 125 130]
[0  0  0  12 0]    [105 110 115 120 125]
[0  0  0  0  0]    [100 105 110 115 120]
</code></pre></div>

<p>计算中心点(2,2)的深度：</p>
<ol>
<li>已知深度点：(1,1)=10m, (3,3)=12m</li>
<li>空间距离：d_1 = √2 ≈ 1.41, d_2 = √2 ≈ 1.41</li>
<li>颜色差异：ΔI_1 = |120-120| = 0, ΔI_2 = |120-120| = 0</li>
<li>权重（σ_s=2, σ_r=10）：</li>
</ol>
<div class="codehilite"><pre><span></span><code>w_s1 = exp(-2/8) = 0.779
w_s2 = exp(-2/8) = 0.779
w_r1 = exp(0) = 1.0
w_r2 = exp(0) = 1.0
</code></pre></div>

<ol start="5">
<li>补全结果：</li>
</ol>
<div class="codehilite"><pre><span></span><code>D(2,2) = (0.779×10 + 0.779×12)/(0.779+0.779) = 11m
</code></pre></div>

<p><strong>性能评估指标：</strong></p>
<ul>
<li>MAE：平均绝对误差 = (1/N)Σ|D_pred - D_gt|</li>
<li>RMSE：均方根误差 = √[(1/N)Σ(D_pred - D_gt)²]</li>
<li>δ_t：阈值精度 = % of pixels where max(D_pred/D_gt, D_gt/D_pred) &lt; t</li>
</ul>
<p><strong>优化技巧：</strong></p>
<ol>
<li>稀疏卷积：仅在有效深度位置计算</li>
<li>置信度传播：从高置信度区域向外扩散</li>
<li>边缘保持：使用法向量一致性约束</li>
</ol>
<h3 id="1115">11.1.5 融合架构设计</h3>
<p>多传感器融合架构的选择直接影响系统性能，需要在精度、效率和可扩展性之间权衡。</p>
<p><strong>前融合（Early Fusion）：</strong></p>
<p>在原始数据层面融合，保留最多的原始信息：</p>
<ol>
<li><strong>数据级融合架构：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>Raw LiDAR Points ──┐
                   ├─→ Joint Representation → Processing → Output
Raw Camera Image ──┘
</code></pre></div>

<ol start="2">
<li><strong>实现方式：</strong></li>
</ol>
<p>a) <strong>图像增强点云：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 为每个3D点添加RGB和纹理特征</span>
<span class="n">enhanced_points</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">lidar_points</span><span class="p">:</span>
    <span class="n">u</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">project_to_image</span><span class="p">(</span><span class="n">point</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">valid_pixel</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="n">rgb</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="n">v</span><span class="p">,</span> <span class="n">u</span><span class="p">]</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="n">compute_gradient</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
        <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">point</span><span class="p">,</span> <span class="n">rgb</span><span class="p">,</span> <span class="n">gradient</span><span class="p">])</span>
        <span class="n">enhanced_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</code></pre></div>

<p>b) <strong>深度增强图像：</strong>
   <code>python
   # 生成RGBD图像
   depth_map = project_lidar_to_depth(lidar_points, K, R, t)
   rgbd_image = np.dstack([rgb_image, depth_map])</code></p>
<ol start="3">
<li><strong>优缺点分析：</strong>
   - 优点：信息保留完整，理论性能上限高
   - 缺点：数据维度高，计算复杂度O(N×M)
   - 适用场景：计算资源充足，追求最高精度</li>
</ol>
<p><strong>后融合（Late Fusion）：</strong></p>
<p>各传感器独立处理后融合结果：</p>
<ol>
<li><strong>决策级融合架构：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>LiDAR → Detector_L → Boxes_L ──┐
                               ├─→ Fusion → Final Boxes
Camera → Detector_C → Boxes_C ─┘
</code></pre></div>

<ol start="2">
<li><strong>融合算法：</strong></li>
</ol>
<p>a) <strong>贝叶斯融合：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">bayesian_fusion</span><span class="p">(</span><span class="n">detections_lidar</span><span class="p">,</span> <span class="n">detections_camera</span><span class="p">):</span>
    <span class="c1"># 计算联合概率</span>
    <span class="n">P_joint</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">box_l</span> <span class="ow">in</span> <span class="n">detections_lidar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">box_c</span> <span class="ow">in</span> <span class="n">detections_camera</span><span class="p">:</span>
            <span class="n">iou</span> <span class="o">=</span> <span class="n">compute_iou</span><span class="p">(</span><span class="n">box_l</span><span class="p">,</span> <span class="n">box_c</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">iou</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
                <span class="c1"># P(object|L,C) = P(L|object)P(C|object)P(object) / P(L,C)</span>
                <span class="n">p_joint</span> <span class="o">=</span> <span class="n">box_l</span><span class="o">.</span><span class="n">conf</span> <span class="o">*</span> <span class="n">box_c</span><span class="o">.</span><span class="n">conf</span> <span class="o">*</span> <span class="n">prior</span><span class="p">[</span><span class="n">box_l</span><span class="o">.</span><span class="n">class</span><span class="p">]</span>
                <span class="n">P_joint</span><span class="p">[(</span><span class="n">box_l</span><span class="p">,</span> <span class="n">box_c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">p_joint</span>

    <span class="c1"># 非极大值抑制</span>
    <span class="k">return</span> <span class="n">nms</span><span class="p">(</span><span class="n">P_joint</span><span class="p">)</span>
</code></pre></div>

<p>b) <strong>匈牙利匹配：</strong>
   ```python
   # 构建代价矩阵
   cost_matrix = np.zeros((len(det_l), len(det_c)))
   for i, box_l in enumerate(det_l):
       for j, box_c in enumerate(det_c):
           cost_matrix[i,j] = matching_cost(box_l, box_c)</p>
<p># 最优匹配
   row_ind, col_ind = linear_sum_assignment(cost_matrix)
   ```</p>
<ol start="3">
<li><strong>置信度融合策略：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code>conf_fused = w_l × conf_l + w_c × conf_c + w_lc × conf_l × conf_c
</code></pre></div>

<p>其中权重通过验证集学习。</p>
<p><strong>深度融合（Deep Fusion）：</strong></p>
<p>在特征层面进行融合，兼顾效率和性能：</p>
<ol>
<li><strong>多级特征融合架构：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeepFusionNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_backbone</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lidar_backbone</span> <span class="o">=</span> <span class="n">PointNet</span><span class="o">++</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_modules</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">FusionBlock</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>  <span class="c1"># Early fusion</span>
            <span class="n">FusionBlock</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>  <span class="c1"># Mid fusion</span>
            <span class="n">FusionBlock</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">)</span> <span class="c1"># Late fusion</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
        <span class="c1"># 提取多尺度特征</span>
        <span class="n">img_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_backbone</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">pts_feats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lidar_backbone</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>

        <span class="c1"># 多级融合</span>
        <span class="n">fused_feats</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">fusion</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fusion_modules</span><span class="p">):</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">fusion</span><span class="p">(</span><span class="n">img_feats</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">pts_feats</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">fused_feats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">fused_feats</span><span class="p">)</span>
</code></pre></div>

<ol start="2">
<li><strong>注意力融合机制：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AttentionFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">q_img</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k_pts</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_pts</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_feat</span><span class="p">,</span> <span class="n">pts_feat</span><span class="p">):</span>
        <span class="c1"># Cross-attention</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_img</span><span class="p">(</span><span class="n">img_feat</span><span class="p">)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_pts</span><span class="p">(</span><span class="n">pts_feat</span><span class="p">)</span>
        <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_pts</span><span class="p">(</span><span class="n">pts_feat</span><span class="p">)</span>

        <span class="n">attn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">Q</span> <span class="o">@</span> <span class="n">K</span><span class="o">.</span><span class="n">T</span> <span class="o">/</span> <span class="err">√</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">fused</span> <span class="o">=</span> <span class="n">attn</span> <span class="o">@</span> <span class="n">V</span>

        <span class="k">return</span> <span class="n">fused</span> <span class="o">+</span> <span class="n">img_feat</span>  <span class="c1"># Residual</span>
</code></pre></div>

<ol start="3">
<li><strong>自适应融合权重：</strong></li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">AdaptiveFusion</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feat_img</span><span class="p">,</span> <span class="n">feat_pts</span><span class="p">):</span>
        <span class="n">concat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">feat_img</span><span class="p">,</span> <span class="n">feat_pts</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_net</span><span class="p">(</span><span class="n">concat</span><span class="p">)</span>  <span class="c1"># [B, 2, H, W]</span>

        <span class="n">fused</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">feat_img</span> <span class="o">+</span> <span class="n">weights</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">feat_pts</span>
        <span class="k">return</span> <span class="n">fused</span>
</code></pre></div>

<p><strong>混合融合架构：</strong></p>
<p>结合多种融合策略的优势：</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HybridFusion</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">early_fusion</span> <span class="o">=</span> <span class="n">PointPainting</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deep_fusion</span> <span class="o">=</span> <span class="n">DeepFusionNet</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">late_fusion</span> <span class="o">=</span> <span class="n">DecisionFusion</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">lidar</span><span class="p">):</span>
        <span class="c1"># 1. 早期融合增强输入</span>
        <span class="n">painted_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">early_fusion</span><span class="p">(</span><span class="n">lidar</span><span class="p">,</span> <span class="n">image</span><span class="p">)</span>

        <span class="c1"># 2. 深度网络处理</span>
        <span class="n">detections_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">deep_fusion</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">painted_points</span><span class="p">)</span>

        <span class="c1"># 3. 独立检测器</span>
        <span class="n">detections_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_detector</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
        <span class="n">detections_pts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pts_detector</span><span class="p">(</span><span class="n">lidar</span><span class="p">)</span>

        <span class="c1"># 4. 后期融合</span>
        <span class="n">final_detections</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">late_fusion</span><span class="p">([</span>
            <span class="n">detections_deep</span><span class="p">,</span>
            <span class="n">detections_img</span><span class="p">,</span>
            <span class="n">detections_pts</span>
        <span class="p">])</span>

        <span class="k">return</span> <span class="n">final_detections</span>
</code></pre></div>

<p><strong>性能对比（KITTI数据集）：</strong></p>
<p>| 融合策略 | Car AP@0.7 | Pedestrian AP@0.5 | Cyclist AP@0.5 | FPS |</p>
<table>
<thead>
<tr>
<th>融合策略</th>
<th>Car AP@0.7</th>
<th>Pedestrian AP@0.5</th>
<th>Cyclist AP@0.5</th>
<th>FPS</th>
</tr>
</thead>
<tbody>
<tr>
<td>仅激光雷达</td>
<td>79.8%</td>
<td>52.1%</td>
<td>67.3%</td>
<td>20</td>
</tr>
<tr>
<td>仅相机</td>
<td>74.2%</td>
<td>45.6%</td>
<td>58.9%</td>
<td>30</td>
</tr>
<tr>
<td>前融合</td>
<td>84.3%</td>
<td>58.2%</td>
<td>73.1%</td>
<td>8</td>
</tr>
<tr>
<td>后融合</td>
<td>82.1%</td>
<td>55.7%</td>
<td>70.8%</td>
<td>15</td>
</tr>
<tr>
<td>深度融合</td>
<td>85.6%</td>
<td>60.3%</td>
<td>74.9%</td>
<td>12</td>
</tr>
<tr>
<td>混合融合</td>
<td>86.9%</td>
<td>61.8%</td>
<td>76.2%</td>
<td>10</td>
</tr>
</tbody>
</table>
<p><strong>工程实践建议：</strong></p>
<ol>
<li><strong>实时系统（&gt;10Hz）：</strong> 优先后融合，计算并行化</li>
<li><strong>高精度需求：</strong> 深度融合或混合融合</li>
<li><strong>传感器异步：</strong> 后融合，独立处理时序</li>
<li><strong>故障容错：</strong> 后融合，便于传感器切换</li>
<li><strong>边缘计算：</strong> 轻量级前融合或后融合</li>
</ol>
<h2 id="112">11.2 激光雷达+毫米波雷达融合</h2>
<p>毫米波雷达能够直接测量目标的径向速度，且在恶劣天气下工作稳定，与激光雷达形成良好互补。</p>
<h3 id="1121">11.2.1 速度信息融合</h3>
<p>毫米波雷达通过多普勒效应测量径向速度：</p>
<div class="codehilite"><pre><span></span><code>f_d = 2v_r f_0/c
v_r = f_d·c/(2f_0)
</code></pre></div>

<p>其中f_0是载波频率（如77GHz），v_r是径向速度。</p>
<p><strong>卡尔曼滤波融合框架：</strong></p>
<p>状态向量：X = [x, y, z, vx, vy, vz]^T</p>
<p>状态转移方程：</p>
<div class="codehilite"><pre><span></span><code>X_k = F·X_{k-1} + w
F = [I₃  Δt·I₃]
    [0₃    I₃ ]
</code></pre></div>

<p>激光雷达观测模型（只有位置）：</p>
<div class="codehilite"><pre><span></span><code>Z_lidar = H_lidar·X + v_lidar
H_lidar = [I₃ 0₃]
</code></pre></div>

<p>毫米波雷达观测模型（位置+径向速度）：</p>
<div class="codehilite"><pre><span></span><code>Z_radar = h_radar(X) + v_radar
h_radar(X) = [x, y, z, (x·vx + y·vy + z·vz)/√(x²+y²+z²)]^T
</code></pre></div>

<p><strong>融合更新步骤：</strong></p>
<ol>
<li>预测：</li>
</ol>
<div class="codehilite"><pre><span></span><code>X̂_k|k-1 = F·X̂_{k-1}
P_k|k-1 = F·P_{k-1}·F^T + Q
</code></pre></div>

<ol start="2">
<li>激光雷达更新：</li>
</ol>
<div class="codehilite"><pre><span></span><code>K_lidar = P_k|k-1·H_lidar^T·(H_lidar·P_k|k-1·H_lidar^T + R_lidar)^{-1}
X̂_k = X̂_k|k-1 + K_lidar·(Z_lidar - H_lidar·X̂_k|k-1)
</code></pre></div>

<ol start="3">
<li>毫米波雷达更新（使用EKF）：</li>
</ol>
<div class="codehilite"><pre><span></span><code>H_radar = ∂h_radar/∂X|_{X̂_k}
K_radar = P_k·H_radar^T·(H_radar·P_k·H_radar^T + R_radar)^{-1}
X̂_k = X̂_k + K_radar·(Z_radar - h_radar(X̂_k))
</code></pre></div>

<p><strong>计算实例：</strong>
目标在(10, 5, 0)m，速度(2, -1, 0)m/s：</p>
<ul>
<li>激光雷达测量：(10.1, 4.9, 0.05)m</li>
<li>毫米波雷达测量：径向速度 v_r = (10×2 + 5×(-1))/√125 = 1.34m/s</li>
</ul>
<p>径向速度验证：</p>
<div class="codehilite"><pre><span></span><code>v_r_true = (x·vx + y·vy)/r = (10×2 + 5×(-1))/11.18 = 1.34m/s ✓
</code></pre></div>

<h3 id="1122">11.2.2 检测置信度融合</h3>
<p>不同传感器对不同目标的检测能力不同，需要融合置信度：</p>
<p><strong>D-S证据理论融合：</strong>
基本概率分配（BPA）：</p>
<ul>
<li>m₁(A)：激光雷达认为是车辆的概率</li>
<li>m₂(A)：毫米波雷达认为是车辆的概率</li>
</ul>
<p>组合规则：</p>
<div class="codehilite"><pre><span></span><code>m(A) = Σ_{B∩C=A} m₁(B)·m₂(C) / (1-K)
K = Σ_{B∩C=∅} m₁(B)·m₂(C)
</code></pre></div>

<p><strong>示例计算：</strong>
对于某目标：</p>
<ul>
<li>激光雷达：m₁(车)=0.7, m₁(人)=0.2, m₁(不确定)=0.1</li>
<li>毫米波：m₂(车)=0.8, m₂(人)=0.1, m₂(不确定)=0.1</li>
</ul>
<p>融合结果：</p>
<div class="codehilite"><pre><span></span><code>K = m₁(车)·m₂(人) + m₁(人)·m₂(车) = 0.7×0.1 + 0.2×0.8 = 0.23
m(车) = (0.7×0.8 + 0.7×0.1 + 0.1×0.8)/(1-0.23) = 0.71/0.77 = 0.922
m(人) = (0.2×0.1 + 0.2×0.1 + 0.1×0.1)/(1-0.23) = 0.05/0.77 = 0.065
</code></pre></div>

<h3 id="1123">11.2.3 恶劣天气互补</h3>
<p><strong>雨雾衰减模型：</strong></p>
<p>激光雷达衰减（905nm）：</p>
<div class="codehilite"><pre><span></span><code>α_lidar_rain ≈ 0.2×R^0.6 dB/km (R: mm/h)
α_lidar_fog ≈ 13×V^{-0.6} dB/km (V: 能见度m)
</code></pre></div>

<p>毫米波雷达衰减（77GHz）：</p>
<div class="codehilite"><pre><span></span><code>α_radar_rain ≈ 0.003×R^1.2 dB/km
α_radar_fog ≈ 0.4 dB/km (轻雾)
</code></pre></div>

<p><strong>互补策略：</strong></p>
<ol>
<li>晴天：激光雷达权重0.8，毫米波0.2</li>
<li>小雨（5mm/h）：激光雷达权重0.6，毫米波0.4</li>
<li>大雨（50mm/h）：激光雷达权重0.3，毫米波0.7</li>
<li>浓雾（V&lt;50m）：激光雷达权重0.1，毫米波0.9</li>
</ol>
<p><strong>自适应权重计算：</strong></p>
<div class="codehilite"><pre><span></span><code>w_lidar = exp(-α_lidar×R) / (exp(-α_lidar×R) + exp(-α_radar×R))
w_radar = 1 - w_lidar
</code></pre></div>

<h3 id="1124">11.2.4 数据关联算法</h3>
<p>激光雷达和毫米波雷达的检测需要正确关联：</p>
<p><strong>最近邻关联：</strong>
马氏距离：</p>
<div class="codehilite"><pre><span></span><code>d²_ij = (z_i - ẑ_j)^T·S^{-1}·(z_i - ẑ_j)
</code></pre></div>

<p>其中S是新息协方差矩阵。</p>
<p><strong>门限判断：</strong></p>
<div class="codehilite"><pre><span></span><code>d²_ij &lt; χ²_α(n)
</code></pre></div>

<p>对于3维位置，95%置信度：χ²_{0.05}(3) = 7.815</p>
<p><strong>全局最优关联（匈牙利算法）：</strong>
构建代价矩阵C，其中C_ij = d²_ij，求解：</p>
<div class="codehilite"><pre><span></span><code>min Σ_i Σ_j C_ij·x_ij
s.t. Σ_i x_ij = 1, Σ_j x_ij = 1, x_ij ∈ {0,1}
</code></pre></div>

<h2 id="113-imu">11.3 激光雷达+IMU融合</h2>
<p>IMU（惯性测量单元）提供高频率的加速度和角速度测量，可以有效补偿激光雷达的运动畸变，提高SLAM精度。</p>
<h3 id="1131-slam">11.3.1 紧耦合SLAM框架</h3>
<p><strong>误差状态卡尔曼滤波（ESKF）：</strong></p>
<p>状态向量（15维）：</p>
<div class="codehilite"><pre><span></span><code>X = [δp, δv, δθ, δb_a, δb_g]^T
</code></pre></div>

<ul>
<li>δp：位置误差</li>
<li>δv：速度误差  </li>
<li>δθ：姿态误差（SO(3)李代数）</li>
<li>δb_a：加速度计偏置误差</li>
<li>δb_g：陀螺仪偏置误差</li>
</ul>
<p><strong>连续时间运动方程：</strong></p>
<div class="codehilite"><pre><span></span><code>ṗ = v
v̇ = R(a - b_a - n_a) - g
Ṙ = R·[ω - b_g - n_g]×
ḃ_a = n_ba
ḃ_g = n_bg
</code></pre></div>

<p><strong>误差状态传播：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">δẋ</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">F</span><span class="err">·</span><span class="n">δx</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">G</span><span class="err">·</span><span class="n">n</span>

<span class="n">F</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">0   I   0     0      0   </span><span class="o">]</span>
<span class="w">    </span><span class="o">[</span><span class="n">0   0  -R[a</span><span class="o">]</span><span class="err">×</span><span class="w"> </span><span class="o">-</span><span class="n">R</span><span class="w">     </span><span class="mi">0</span><span class="w">   </span><span class="err">]</span>
<span class="w">    </span><span class="o">[</span><span class="n">0   0  -[ω</span><span class="o">]</span><span class="err">×</span><span class="w">  </span><span class="mi">0</span><span class="w">     </span><span class="o">-</span><span class="n">I</span><span class="w">   </span><span class="err">]</span>
<span class="w">    </span><span class="o">[</span><span class="n">0   0   0     0      0   </span><span class="o">]</span>
<span class="w">    </span><span class="o">[</span><span class="n">0   0   0     0      0   </span><span class="o">]</span>
</code></pre></div>

<p>其中[a]×表示反对称矩阵：</p>
<div class="codehilite"><pre><span></span><code><span class="k">[a]× = [ 0   -a_z  a_y]</span>
<span class="w">       </span><span class="k">[ a_z  0   -a_x]</span>
<span class="w">       </span><span class="k">[-a_y  a_x  0  ]</span>
</code></pre></div>

<p><strong>离散化（中值积分）：</strong></p>
<div class="codehilite"><pre><span></span><code>δx_k = (I + F·Δt)·δx_{k-1} + G·n·√Δt
P_k = Φ·P_{k-1}·Φ^T + Q_d
</code></pre></div>

<h3 id="1132-imu">11.3.2 IMU预积分理论</h3>
<p>预积分避免了每次优化时重新积分IMU数据：</p>
<p><strong>位置预积分：</strong></p>
<div class="codehilite"><pre><span></span><code>Δp_{ij} = ∫_i^j ∫_i^t R_s(a_s - b_a)dsdt - (t_j-t_i)²g/2
</code></pre></div>

<p><strong>速度预积分：</strong></p>
<div class="codehilite"><pre><span></span><code>Δv_{ij} = ∫_i^j R_t(a_t - b_a)dt - (t_j-t_i)g
</code></pre></div>

<p><strong>旋转预积分：</strong></p>
<div class="codehilite"><pre><span></span><code>ΔR_{ij} = ∏_{k=i}^{j-1} Exp((ω_k - b_g)Δt)
</code></pre></div>

<p>其中Exp是SO(3)指数映射：</p>
<div class="codehilite"><pre><span></span><code>Exp(ω) = I + sin(||ω||)/||ω||·[ω]× + (1-cos(||ω||))/||ω||²·[ω]×²
</code></pre></div>

<p><strong>预积分测量的雅可比：</strong>
对于偏置变化的一阶近似：</p>
<div class="codehilite"><pre><span></span><code>Δp̃_{ij} ≈ Δp_{ij} + J_p^{ba}·δb_a + J_p^{bg}·δb_g
Δṽ_{ij} ≈ Δv_{ij} + J_v^{ba}·δb_a + J_v^{bg}·δb_g
ΔR̃_{ij} ≈ ΔR_{ij}·Exp(J_R^{bg}·δb_g)
</code></pre></div>

<p><strong>计算实例：</strong>
两个关键帧之间，IMU采样100Hz，持续0.5秒：</p>
<ul>
<li>平均加速度：a = [0.1, 0, 9.85] m/s²（包含重力）</li>
<li>平均角速度：ω = [0, 0, 0.1] rad/s</li>
<li>偏置：b_a = [0.01, 0.01, 0], b_g = [0.001, 0.001, 0.002]</li>
</ul>
<p>预积分结果：</p>
<div class="codehilite"><pre><span></span><code>Δv = ∫(a - b_a)dt - tg = [0.045, -0.005, 0.125] m/s
Δp = ∫∫(a - b_a)dtdt - t²g/2 = [0.011, -0.001, 0.031] m
ΔR = Exp((ω - b_g)t) ≈ Exp([0, 0, 0.049])
</code></pre></div>

<h3 id="1133">11.3.3 运动畸变校正</h3>
<p>激光雷达扫描期间的运动导致点云畸变：</p>
<p><strong>线性插值方法：</strong>
对于时刻t_i的点P_i，校正到参考时刻t_0：</p>
<div class="codehilite"><pre><span></span><code>P_0 = R_{0i}^{-1}(P_i - t_{0i})
</code></pre></div>

<p>其中R_{0i}和t_{0i}通过IMU积分获得：</p>
<div class="codehilite"><pre><span></span><code>R_{0i} = R_0·∏_{k=0}^{i-1} Exp(ω_k·Δt)
t_{0i} = Σ_{k=0}^{i-1} v_k·Δt + 0.5·a_k·Δt²
</code></pre></div>

<p><strong>去畸变算法流程：</strong></p>
<ol>
<li>对每个激光点，记录其时间戳t_i</li>
<li>从IMU获取[t_0, t_i]期间的测量</li>
<li>积分得到相对位姿变换</li>
<li>将点变换到统一坐标系</li>
</ol>
<p><strong>实际案例：</strong>
车辆以20m/s行驶，激光雷达10Hz旋转：</p>
<ul>
<li>一圈扫描时间：100ms</li>
<li>位移：20×0.1 = 2m</li>
<li>不校正误差：最大2m</li>
</ul>
<p>使用IMU（200Hz）校正：</p>
<ul>
<li>每5ms更新一次位姿</li>
<li>最大误差降至：20×0.005 = 0.1m</li>
</ul>
<h3 id="1134">11.3.4 状态估计优化</h3>
<p><strong>图优化框架：</strong>
构建因子图，包含：</p>
<ul>
<li>IMU因子：基于预积分</li>
<li>激光雷达因子：点到面距离</li>
<li>回环因子：位姿约束</li>
</ul>
<p><strong>代价函数：</strong></p>
<div class="codehilite"><pre><span></span><code>min Σ||r_IMU||²_{Σ_IMU} + Σ||r_LiDAR||²_{Σ_LiDAR} + Σ||r_loop||²_{Σ_loop}
</code></pre></div>

<p><strong>IMU残差：</strong></p>
<div class="codehilite"><pre><span></span><code>r_IMU = [R_i^T(p_j - p_i - v_i·Δt - g·Δt²/2) - Δp_{ij}]
        [R_i^T(v_j - v_i - g·Δt) - Δv_{ij}        ]
        [Log(ΔR_{ij}^T·R_i^T·R_j)                 ]
</code></pre></div>

<p><strong>LiDAR残差（点到面）：</strong></p>
<div class="codehilite"><pre><span></span><code>r_LiDAR = n^T·(R·p + t - q)
</code></pre></div>

<p>其中n是平面法向量，q是平面上的点。</p>
<p><strong>优化求解：</strong>
使用Levenberg-Marquardt算法：</p>
<div class="codehilite"><pre><span></span><code>(J^T·W·J + λI)·Δx = -J^T·W·r
</code></pre></div>

<h3 id="1135">11.3.5 传感器标定</h3>
<p><strong>IMU-LiDAR外参标定：</strong>
旋转外参R_IL，平移外参t_IL</p>
<p>标定优化问题：</p>
<div class="codehilite"><pre><span></span><code>min Σ||p_L^j - R_IL·R_IB·(p_L^i - t_IL) - t_IL - R_IL·t_IB||²
</code></pre></div>

<p><strong>时间偏移标定：</strong>
IMU和LiDAR可能存在时间偏移t_d：</p>
<div class="codehilite"><pre><span></span><code>t_IMU = t_LiDAR + t_d
</code></pre></div>

<p>通过最大化角速度相关性估计：</p>
<div class="codehilite"><pre><span></span><code>t_d = argmax Corr(ω_IMU(t), ω_LiDAR(t-τ))
</code></pre></div>

<h2 id="114-gpsrtk">11.4 激光雷达+GPS/RTK融合</h2>
<p>GPS/RTK提供全局定位信息，可以消除SLAM的累积误差，实现大范围高精度定位。</p>
<h3 id="1141">11.4.1 全局定位融合框架</h3>
<p><strong>图优化模型：</strong>
节点：机器人位姿X_i = [x, y, z, roll, pitch, yaw]^T
边：</p>
<ul>
<li>里程计边：相邻帧间的相对位姿</li>
<li>GPS边：绝对位置约束</li>
<li>回环边：闭环检测约束</li>
</ul>
<p><strong>代价函数：</strong></p>
<div class="codehilite"><pre><span></span><code>E = Σ||X_j ⊖ X_i ⊖ Z_{ij}^{odom}||²_{Σ_{ij}} 

  + Σ||p_i - Z_i^{GPS}||²_{Σ_{GPS}}
  + Σ||X_j ⊖ X_i ⊖ Z_{ij}^{loop}||²_{Σ_{loop}}
</code></pre></div>

<p>其中⊖表示SE(3)上的误差运算。</p>
<p><strong>GPS测量模型：</strong></p>
<div class="codehilite"><pre><span></span><code>Z_GPS = p_true + R_ENU·[σ_N·n_N, σ_E·n_E, σ_U·n_U]^T
</code></pre></div>

<ul>
<li>σ_N, σ_E, σ_U：北东天方向的标准差</li>
<li>RTK定位：σ_N = σ_E ≈ 0.01m, σ_U ≈ 0.02m</li>
<li>普通GPS：σ_N = σ_E ≈ 2-5m, σ_U ≈ 5-10m</li>
</ul>
<p><strong>ENU坐标转换：</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">[E]   [-sin(lon)          cos(lon)           0    ] [X_ECEF]</span>
<span class="k">[N] = [-sin(lat)cos(lon) -sin(lat)sin(lon)  cos(lat)] [Y_ECEF]</span>
<span class="k">[U]   [cos(lat)cos(lon)   cos(lat)sin(lon)  sin(lat)] [Z_ECEF]</span>
</code></pre></div>

<h3 id="1142">11.4.2 多路径效应处理</h3>
<p>城市环境中的GPS信号受建筑物反射影响：</p>
<p><strong>多路径检测指标：</strong></p>
<ol>
<li>C/N₀（载噪比）：&lt; 35 dB-Hz表示信号弱</li>
<li>仰角：&lt; 15°的卫星易受多路径影响</li>
<li>DOP值：PDOP &gt; 4表示几何构型差</li>
</ol>
<p><strong>鲁棒估计方法：</strong>
使用Huber损失函数：</p>
<div class="codehilite"><pre><span></span><code>ρ(e) = {
    0.5·e²,           |e| ≤ δ
    δ(|e| - 0.5δ),   |e| &gt; δ
}
</code></pre></div>

<p>权重函数：</p>
<div class="codehilite"><pre><span></span><code>w(e) = {
    1,        |e| ≤ δ
    δ/|e|,    |e| &gt; δ
}
</code></pre></div>

<p><strong>示例计算：</strong>
GPS测量值与预测值偏差e = 5m，阈值δ = 2m：</p>
<ul>
<li>二次损失：L = 0.5×5² = 12.5</li>
<li>Huber损失：L = 2×(5-0.5×2) = 8</li>
<li>权重：w = 2/5 = 0.4</li>
</ul>
<h3 id="1143">11.4.3 城市峡谷问题</h3>
<p>高楼环境导致GPS信号遮挡和反射：</p>
<p><strong>可见性预测：</strong>
使用激光雷达构建的3D地图预测卫星可见性：</p>
<div class="codehilite"><pre><span></span><code>Visible(sat_i) = RayCast(p_receiver, p_satellite) == clear
</code></pre></div>

<p><strong>天空视野因子（SVF）：</strong></p>
<div class="codehilite"><pre><span></span><code>SVF = Σ_visible cos(θ_elevation) / Σ_all cos(θ_elevation)
</code></pre></div>

<p><strong>融合策略：</strong></p>
<ol>
<li>SVF &gt; 0.7：正常融合GPS</li>
<li>0.3 &lt; SVF &lt; 0.7：降低GPS权重</li>
<li>SVF &lt; 0.3：仅依赖激光雷达SLAM</li>
</ol>
<p><strong>自适应协方差调整：</strong></p>
<div class="codehilite"><pre><span></span><code>Σ_GPS_adjusted = Σ_GPS_base × (2 - SVF)²
</code></pre></div>

<h3 id="1144-vs">11.4.4 松耦合vs紧耦合</h3>
<p><strong>松耦合架构：</strong></p>
<ul>
<li>GPS/RTK独立解算位置</li>
<li>作为位置约束加入SLAM</li>
<li>优点：模块化，计算简单</li>
<li>缺点：未充分利用原始观测</li>
</ul>
<p><strong>紧耦合架构：</strong></p>
<ul>
<li>使用GPS原始伪距/载波相位观测</li>
<li>与激光雷达联合优化</li>
<li>优点：精度高，鲁棒性好</li>
<li>缺点：计算复杂</li>
</ul>
<p><strong>伪距观测方程：</strong></p>
<div class="codehilite"><pre><span></span><code>ρ = ||p_sat - p_rec|| + c(dt_rec - dt_sat) + I + T + ε
</code></pre></div>

<ul>
<li>I：电离层延迟</li>
<li>T：对流层延迟</li>
<li>ε：多路径和噪声</li>
</ul>
<h3 id="1145">11.4.5 初始化与收敛</h3>
<p><strong>全局初始化：</strong></p>
<ol>
<li>等待GPS锁定（至少4颗卫星）</li>
<li>静止30秒收集IMU数据估计初始姿态</li>
<li>使用GPS位置和IMU姿态初始化</li>
</ol>
<p><strong>局部到全局坐标转换：</strong>
激光雷达SLAM通常在局部坐标系工作，需要估计到全局坐标系的变换：</p>
<div class="codehilite"><pre><span></span><code>T_global_local = argmin Σ||T·p_i^local - p_i^GPS||²
</code></pre></div>

<p>使用SVD求解：</p>
<ol>
<li>计算质心：p̄_local, p̄_GPS</li>
<li>去质心：p'_i = p_i - p̄</li>
<li>计算H = Σp'_local·p'_GPS^T</li>
<li>SVD分解：H = UΣV^T</li>
<li>旋转：R = VU^T</li>
<li>平移：t = p̄_GPS - R·p̄_local</li>
</ol>
<p><strong>收敛监测：</strong></p>
<div class="codehilite"><pre><span></span><code>converged = (||Δposition|| &lt; 0.1m) &amp;&amp; (||Δorientation|| &lt; 1°)
</code></pre></div>

<h2 id="_1">本章小结</h2>
<p>本章详细介绍了激光雷达与相机、毫米波雷达、IMU和GPS/RTK的融合算法。主要知识点包括：</p>
<ol>
<li>
<p><strong>激光雷达+相机融合</strong>：
   - 投影矩阵计算：P = K[R|t]
   - 时间同步策略：硬件触发和软件插值
   - PointPainting特征融合
   - 深度补全算法</p>
</li>
<li>
<p><strong>激光雷达+毫米波雷达融合</strong>：
   - 卡尔曼滤波框架融合速度信息
   - D-S证据理论融合检测置信度
   - 恶劣天气下的互补策略
   - 数据关联算法</p>
</li>
<li>
<p><strong>激光雷达+IMU融合</strong>：
   - 误差状态卡尔曼滤波（ESKF）
   - IMU预积分理论：Δp, Δv, ΔR
   - 运动畸变校正
   - 紧耦合SLAM优化</p>
</li>
<li>
<p><strong>激光雷达+GPS/RTK融合</strong>：
   - 图优化融合框架
   - 多路径效应和城市峡谷问题处理
   - 松耦合vs紧耦合架构
   - 坐标系转换和初始化</p>
</li>
</ol>
<p>多传感器融合的核心是充分利用各传感器的优势，通过合理的数学框架实现信息互补，提高系统的鲁棒性和精度。在实际应用中，需要根据具体场景选择合适的融合策略。</p>
<h2 id="_2">练习题</h2>
<h3 id="_3">基础题</h3>
<ol>
<li><strong>坐标转换计算</strong>
   激光雷达检测到点P_lidar = [5, 3, 1]m，已知外参：R = Rz(30°), t = [0.2, 0.1, 0.3]m，相机内参fx=fy=800, cx=640, cy=480。计算该点在图像中的坐标。</li>
</ol>
<p><em>Hint: 先进行坐标系转换，再投影到图像平面</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   1. 旋转矩阵Rz(30°) = [[0.866, -0.5, 0], [0.5, 0.866, 0], [0, 0, 1]]
   2. P_camera = R·P_lidar + t = [3.03, 3.10, 1.3]m
   3. u = 800×3.03/1.3 + 640 = 2505, v = 800×3.10/1.3 + 480 = 2387
   </details>
<ol start="2">
<li><strong>卡尔曼滤波预测</strong>
   目标当前状态x=[10, 5, 2, -1]（位置和速度），Δt=0.1s，计算预测状态。</li>
</ol>
<p><em>Hint: 使用匀速运动模型</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   F = [[1, 0, 0.1, 0], [0, 1, 0, 0.1], [0, 0, 1, 0], [0, 0, 0, 1]]
   x_pred = F·x = [10.2, 4.9, 2, -1]
   </details>
<ol start="3">
<li><strong>IMU预积分计算</strong>
   IMU测量加速度a=[0.1, 0, 9.81]m/s²，角速度ω=[0, 0, 0.1]rad/s，时间间隔0.5s，计算速度和位置变化。</li>
</ol>
<p><em>Hint: 忽略重力，假设初始速度为0</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   Δv = a×t = [0.05, 0, 4.905]m/s
   Δp = 0.5×a×t² = [0.0125, 0, 1.226]m
   </details>
<h3 id="_4">挑战题</h3>
<ol start="4">
<li><strong>深度补全算法设计</strong>
   设计一个基于双边滤波的深度补全算法，考虑颜色相似性和空间距离。给出权重计算公式和实现伪代码。</li>
</ol>
<p><em>Hint: 参考双边滤波的数学形式</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   权重：w(p,q) = exp(-||p-q||²/2σ_s²) × exp(-||I_p-I_q||²/2σ_r²)
   深度：D(p) = Σw(p,q)×D(q) / Σw(p,q)
   伪代码：遍历窗口内所有像素，计算权重，加权平均
   </details>
<ol start="5">
<li><strong>多传感器时间同步</strong>
   激光雷达10Hz，相机30Hz，IMU 200Hz。设计一个时间同步方案，确保数据对齐误差小于5ms。</li>
</ol>
<p><em>Hint: 考虑硬件触发和软件插值</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   1. 使用GPS的PPS信号作为公共时钟
   2. 激光雷达触发相机，确保3:1同步
   3. IMU数据通过插值对齐到激光雷达时刻
   4. 维护时间戳缓冲区，使用最近邻匹配
   </details>
<ol start="6">
<li><strong>城市峡谷GPS融合策略</strong>
   在城市峡谷环境中，设计一个自适应的GPS权重调整策略，考虑卫星数量、DOP值和信号强度。</li>
</ol>
<p><em>Hint: 使用多个指标综合评估GPS质量</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   质量因子Q = w1×(n_sat/12) + w2×(4/PDOP) + w3×(CNR/50)
   GPS权重 = min(Q, 1.0)
   当Q &lt; 0.3时，完全依赖激光雷达SLAM
   </details>
<ol start="7">
<li><strong>IMU零偏在线估计</strong>
   设计一个算法，在车辆静止时在线估计IMU的加速度计和陀螺仪零偏。</li>
</ol>
<p><em>Hint: 静止时理论加速度应为重力，角速度应为0</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   静止检测：||a|| ∈ [9.7, 9.9] &amp;&amp; ||ω|| &lt; 0.01
   加速度计零偏：b_a = mean(a) - g_ref
   陀螺仪零偏：b_g = mean(ω)
   使用滑动窗口避免异常值
   </details>
<ol start="8">
<li><strong>多传感器标定验证</strong>
   设计一个实验方案，验证激光雷达-相机外参标定的准确性，要求精度达到像素级。</li>
</ol>
<p><em>Hint: 使用标定板或自然特征点</em></p>
<details markdown="block">
   <summary markdown="off">答案</summary>

   1. 使用棋盘格标定板，激光雷达提取平面，相机检测角点
   2. 投影激光雷达平面边缘到图像，计算与检测边缘的偏差
   3. 统计多个位置的重投影误差RMS
   4. 误差应小于2像素，否则重新标定
   </details>
            </article>
            
            <nav class="page-nav"><a href="chapter10.html" class="nav-link prev">← Chapter 10: 标定技术</a><a href="chapter12.html" class="nav-link next">Chapter 12: 自动驾驶专用章节 →</a></nav>
        </main>
    </div>
</body>
</html>